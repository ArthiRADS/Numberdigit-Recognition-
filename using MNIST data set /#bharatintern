import tensorflow as tf
from tensorflow import keras
import matplotlib.pyplot as plt
# Load the MNIST dataset
mnist = keras.datasets.mnist
(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train.shape
plt.figure(figsize=(5, 9))
for i in range(25):
    plt.subplot(5, 5, i + 1)
    plt.imshow(x_train[i], cmap='gray')
    plt.title(f"Label: {y_train[i]}")
    plt.axis('off')  # Turn off axis labels
plt.show()
import matplotlib.pyplot as plt

# Display the first image from the x_train dataset with a binary colormap
plt.imshow(x_train[0], cmap=plt.cm.binary)
plt.show()
print(x_train[0])
#Normalize the data || pre-processing step
import matplotlib.pyplot as plt
plt.imshow(x_train[0], cmap=plt.cm.binary)
plt.show()

# Normalize the test data using x_test, not x_train
x_test = tf.keras.utils.normalize(x_test, axis=1)
print(x_train[0])
print(y_train[0])

#Resizing image to make it suitable for apply convolution operation

import numpy as np

IMG_SIZE = 28  # Correct the variable name to IMG_SIZE
x_trainr = np.array(x_train).reshape(-1, IMG_SIZE, IMG_SIZE, 1)
x_testr = np.array(x_test).reshape(-1, IMG_SIZE, IMG_SIZE, 1)  # Correct the variable to x_test
print("Training samples dimension", x_trainr.shape)
print("Testing samples dimension", x_testr.shape)
#Training on 60,000 smaples of MNIST handwritten dataset
import tensorflow as tf
from tensorflow import keras
# Normalize pixel values to a range between 0 and 1
x_train, x_test = x_train / 255.0, x_test / 255.0

model = keras.models.Sequential([
    keras.layers.Flatten(input_shape=(28, 28)),  # Flatten 28x28 images to a 1D vector
    keras.layers.Dense(128, activation='relu'),  # Fully connected layer with ReLU activation
    keras.layers.Dropout(0.2),  # Dropout layer to reduce overfitting
    keras.layers.Dense(10, activation='softmax')  # Output layer with 10 classes for digits 0-9
])
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])
model.fit(x_train, y_train, epochs=5)

# Evaluate the model on the test data
test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)
print("\nTest accuracy:", test_acc)
print("Total Training Samples=",len(x_trainr))

model.fit(x_trainr,y_train,epochs=5,validation_split=0.3)
test_loss, test_acc = model.evaluate(x_test, y_test)
print("Test Loss on 10,000 test samples:", test_loss)
print("Validation Accuracy on 10,000 test samples:", test_acc)
prediction=model.predict([x_testr])
print(prediction)
print(np.argmax(prediction[0]))

plt.imshow(x_test[0])

import numpy as np
image_index = 0
predicted_label = np.argmax(prediction[image_index])
actual_label = y_test[image_index]
print("Predicted Label:", predicted_label)
print("Actual Label:", actual_label)
if predicted_label == actual_label:
    print("Prediction is correct.")
else:
    print("Prediction is incorrect.")
plt.imshow(x_test[0])
print(np.argmax(prediction[128]))
plt.imshow(x_test[128])






